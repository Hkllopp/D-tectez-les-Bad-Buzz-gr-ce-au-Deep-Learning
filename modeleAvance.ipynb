{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele Avance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la différence du notebook précédent, ici les deux étapes servant à faire la prédiction vont être remplacée :\n",
    "- La traduction du mot en vecteur (word embedding) ne sera plus assurée par un CountVectorizer (qui ne faisait que compter les mots dans la phrase) mais par un modèle déjà entrainé qui place chaque mot comme un point dans un espace de grande dimension (word2vec ou GloVe)\n",
    "- L'étape de prédiction, qui était faite avec une régression logistique sera assurée par un réseau de neurone mis en bout de chaine du modèle de word embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "This is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import csv\n",
    "raw_data = pd.read_csv('data/training.1600000.processed.noemoticon.csv', encoding='latin-1', names=['target', 'ids', 'date', 'flag', 'user', 'text'])\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "It contains the following 6 fields:\n",
    "1. target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "2. ids: The id of the tweet\n",
    "3. date: the date of the tweet\n",
    "4. flag: The query. If there is no query, then this value is NO_QUERY.\n",
    "5. user: the user that tweeted\n",
    "6. text: the text of the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy(deep=True)\n",
    "data['target'] = data['target'].map(lambda x: 1 if x == 4 else 0).astype('bool')\n",
    "data['ids'] = data['ids'].astype('str')\n",
    "data['date'] = data['date'].astype('str') # We will convert them to date if useful later, now we just want to reduce the size of the dataframe\n",
    "data['flag'] = data['flag'].astype('str')\n",
    "data['user'] = data['user'].astype('str')\n",
    "data['text'] = data['text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target bool\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: target, dtype: bool\n",
      "False    800000\n",
      "True     800000\n",
      "Name: target, dtype: int64\n",
      "\n",
      "\n",
      "ids object\n",
      "0    1467810369\n",
      "1    1467810672\n",
      "2    1467810917\n",
      "3    1467811184\n",
      "4    1467811193\n",
      "Name: ids, dtype: object\n",
      "2190457769    2\n",
      "1972193428    2\n",
      "1989776729    2\n",
      "1989776908    2\n",
      "1564543229    2\n",
      "             ..\n",
      "2197311196    1\n",
      "2197311146    1\n",
      "2197310899    1\n",
      "2197310477    1\n",
      "2193602129    1\n",
      "Name: ids, Length: 1598315, dtype: int64\n",
      "\n",
      "\n",
      "date object\n",
      "0    Mon Apr 06 22:19:45 PDT 2009\n",
      "1    Mon Apr 06 22:19:49 PDT 2009\n",
      "2    Mon Apr 06 22:19:53 PDT 2009\n",
      "3    Mon Apr 06 22:19:57 PDT 2009\n",
      "4    Mon Apr 06 22:19:57 PDT 2009\n",
      "Name: date, dtype: object\n",
      "Mon Jun 15 12:53:14 PDT 2009    20\n",
      "Fri May 29 13:40:04 PDT 2009    17\n",
      "Fri May 22 05:10:17 PDT 2009    17\n",
      "Mon Jun 15 13:39:50 PDT 2009    17\n",
      "Fri Jun 05 14:13:07 PDT 2009    16\n",
      "                                ..\n",
      "Sun Jun 07 12:36:07 PDT 2009     1\n",
      "Sun Jun 07 12:36:04 PDT 2009     1\n",
      "Sun Jun 07 12:36:03 PDT 2009     1\n",
      "Sun Jun 07 12:36:02 PDT 2009     1\n",
      "Tue Jun 16 08:40:50 PDT 2009     1\n",
      "Name: date, Length: 774363, dtype: int64\n",
      "\n",
      "\n",
      "flag object\n",
      "0    NO_QUERY\n",
      "1    NO_QUERY\n",
      "2    NO_QUERY\n",
      "3    NO_QUERY\n",
      "4    NO_QUERY\n",
      "Name: flag, dtype: object\n",
      "NO_QUERY    1600000\n",
      "Name: flag, dtype: int64\n",
      "\n",
      "\n",
      "user object\n",
      "0    _TheSpecialOne_\n",
      "1      scotthamilton\n",
      "2           mattycus\n",
      "3            ElleCTF\n",
      "4             Karoli\n",
      "Name: user, dtype: object\n",
      "lost_dog           549\n",
      "webwoke            345\n",
      "tweetpet           310\n",
      "SallytheShizzle    281\n",
      "VioletsCRUK        279\n",
      "                  ... \n",
      "67trinity            1\n",
      "Sibby                1\n",
      "mAnyA_15             1\n",
      "49ersfan111          1\n",
      "bpbabe               1\n",
      "Name: user, Length: 659775, dtype: int64\n",
      "\n",
      "\n",
      "text object\n",
      "0    @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1    is upset that he can't update his Facebook by ...\n",
      "2    @Kenichan I dived many times for the ball. Man...\n",
      "3      my whole body feels itchy and like its on fire \n",
      "4    @nationwideclass no, it's not behaving at all....\n",
      "Name: text, dtype: object\n",
      "isPlayer Has Died! Sorry                                                                              210\n",
      "good morning                                                                                          118\n",
      "headache                                                                                              115\n",
      "Good morning                                                                                          112\n",
      "Headache                                                                                              106\n",
      "                                                                                                     ... \n",
      "braces  tell me it will be okay...                                                                      1\n",
      "is stuck at home without curry                                                                          1\n",
      "@mrsduryee I've applied to about 70 since I lost my job in March...it certainly FEELS like a lot!       1\n",
      "The cheese I got @SarawithanR lost its squeak                                                           1\n",
      "happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H                                           1\n",
      "Name: text, Length: 1581466, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(col, data[col].dtype)\n",
    "    print(data[col].head())\n",
    "    print(data[col].value_counts())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179 stopwords in the original list\n",
      "137 stopwords after removing the negative words\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "print(f\"{len(stopwords)} stopwords in the original list\")\n",
    "[stopwords.remove(negative_word) for negative_word in ['t', 'against', 'no', 'nor', 'not', 'don', \"don't\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]]\n",
    "print(f\"{len(stopwords)} stopwords after removing the negative words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "# We should later implement the same preprocessing process [here](https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb)\n",
    "\n",
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    \n",
    "    # Create Lemmatizer and Stemmer.\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    \n",
    "    # Defining regex patterns.\n",
    "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()\n",
    "        \n",
    "        # Replace all URls with 'URL'\n",
    "        tweet = re.sub(urlPattern,' URL',tweet)    \n",
    "        # Replace @USERNAME to 'USER'.\n",
    "        tweet = re.sub(userPattern,' USER', tweet)        \n",
    "        # Replace all non alphabets.\n",
    "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "        # Replace 3 or more consecutive letters by 2 letter.\n",
    "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "            #if word not in stopwordlist:\n",
    "            if word not in stopwords:\n",
    "                # Lemmatizing the word.\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                tweetwords += (word+' ')\n",
    "                \n",
    "        processedText.append(tweetwords)        \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing took 107.09063744544983 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "corpus = data['text']\n",
    "t = time.time()\n",
    "X = preprocess(corpus)\n",
    "print(f\"Preprocessing took {time.time()-t} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = data['target']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the tweets are cleaned, we will create a dictionnary where every key is a number and value is a word and replace every word by its number in the tweets.\n",
    "Then, we will padd these tweets in order to have a uniform length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size : 248879\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size :\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X Shape: (1280000, 180)\n",
      "Testing X Shape: (320000, 180)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 180\n",
    "\n",
    "X_train = tf.keras.utils.pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen = MAX_SEQUENCE_LENGTH)\n",
    "X_test = tf.keras.utils.pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen = MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(\"Training X Shape:\",X_train.shape)\n",
    "print(\"Testing X Shape:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to 'twitter': [('facebook', 0.948005199432373), ('tweet', 0.9403423070907593), ('fb', 0.9342358708381653), ('instagram', 0.9104824066162109), ('chat', 0.8964964747428894), ('hashtag', 0.8885937333106995), ('tweets', 0.8878158330917358), ('tl', 0.8778461217880249), ('link', 0.8778210878372192), ('internet', 0.8753897547721863)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "# Word2vec\n",
    "import gensim.downloader\n",
    "\n",
    "# we could train the model but in order to save time, we will load a model already trained on 2B tweets ([see here](https://github.com/RaRe-Technologies/gensim-data))\n",
    "glove_vectors = gensim.downloader.load('glove-twitter-25') # Already 104MB\n",
    "VECTORS_DIM = 25 # because twitter-25\n",
    "\n",
    "glove_vectors.most_similar('twitter')\n",
    "\n",
    "print(f\"Most similar to 'twitter': {glove_vectors.most_similar('twitter')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé une liste de mots de notre tokenizer et on va y associer les vecteurs qu'on a trouvé dans le modèle qu'on vient de charger. La couche Embedding servira donc juste à associer les mots (leurs numéros) à leur vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# convert the wv word vectors into a numpy matrix that is suitable for insertion into our TensorFlow and Keras models\n",
    "embedding_matrix = np.zeros((vocab_size, VECTORS_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if glove_vectors.has_index_for(word):\n",
    "        embedding_matrix[i] = glove_vectors.get_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=VECTORS_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding_sequences = embedding_layer(sequence_input)\n",
    "x = SpatialDropout1D(0.2)(embedding_sequences)\n",
    "x = Conv1D(64, 5, activation='relu')(x)\n",
    "x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(sequence_input, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\modeleAvance.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/augustin/Desktop/Projets/Formations/Openclassrooms/Projet%207/D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning/modeleAvance.ipynb#ch0000016?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/augustin/Desktop/Projets/Formations/Openclassrooms/Projet%207/D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning/modeleAvance.ipynb#ch0000016?line=5'>6</a>\u001b[0m ReduceLROnPlateau \u001b[39m=\u001b[39m ReduceLROnPlateau(factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, min_lr \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m, monitor \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, verbose \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/augustin/Desktop/Projets/Formations/Openclassrooms/Projet%207/D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning/modeleAvance.ipynb#ch0000016?line=7'>8</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, batch_size \u001b[39m=\u001b[39;49m \u001b[39m1024\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, Y_test), callbacks\u001b[39m=\u001b[39;49m[ReduceLROnPlateau])\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2452\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m-> 2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[39m=\u001b[39m cache_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2629\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2630\u001b[0m         args,\n\u001b[0;32m   2631\u001b[0m         kwargs,\n\u001b[0;32m   2632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2633\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2634\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2635\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2636\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1116\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m   1117\u001b[0m       original_func,\n\u001b[0;32m   1118\u001b[0m       args,\n\u001b[0;32m   1119\u001b[0m       kwargs,\n\u001b[0;32m   1120\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m   1121\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1122\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m   1123\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1124\u001b[0m       ))\n\u001b[0;32m   1125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file54n7oxv3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\keras\\engine\\training.py:1040\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1038\u001b[0m       run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1039\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1040\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1041\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1042\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1043\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1308\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1311\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1312\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2887\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2888\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3688\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3689\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\keras\\engine\\training.py:1030\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1031\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\keras\\engine\\training.py:893\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    892\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 893\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    894\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:537\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    507\u001b[0m   \u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[0;32m    509\u001b[0m \u001b[39m  This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_gradients(\n\u001b[0;32m    538\u001b[0m       loss, var_list\u001b[39m=\u001b[39;49mvar_list, grad_loss\u001b[39m=\u001b[39;49mgrad_loss, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    539\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:590\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    588\u001b[0m var_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(var_list)\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/gradients\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 590\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_gradients(tape, loss, var_list, grad_loss)\n\u001b[0;32m    592\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_valid_dtypes([\n\u001b[0;32m    593\u001b[0m     v \u001b[39mfor\u001b[39;00m g, v \u001b[39min\u001b[39;00m grads_and_vars\n\u001b[0;32m    594\u001b[0m     \u001b[39mif\u001b[39;00m g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m v\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m tf\u001b[39m.\u001b[39mresource\n\u001b[0;32m    595\u001b[0m ])\n\u001b[0;32m    597\u001b[0m \u001b[39mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:471\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gradients\u001b[39m(\u001b[39mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    470\u001b[0m   \u001b[39m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m   grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, var_list, grad_loss)\n\u001b[0;32m    472\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1102\u001b[0m     flat_targets,\n\u001b[0;32m   1103\u001b[0m     flat_sources,\n\u001b[0;32m   1104\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1105\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1106\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[0;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:438\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    435\u001b[0m   \u001b[39mreturn\u001b[39;00m counter \u001b[39m<\u001b[39m forward_loop_iters\n\u001b[0;32m    437\u001b[0m grad_cond_name \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39munique_grad_fn_name(op\u001b[39m.\u001b[39mget_attr(\u001b[39m\"\u001b[39m\u001b[39mcond\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mname)\n\u001b[1;32m--> 438\u001b[0m cond_grad_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    439\u001b[0m     grad_cond_name, grad_cond, loop_vars, {},\n\u001b[0;32m    440\u001b[0m     func_graph\u001b[39m=\u001b[39;49mutil\u001b[39m.\u001b[39;49mWhileCondFuncGraph(grad_cond_name))\n\u001b[0;32m    442\u001b[0m _check_num_inputs_outputs(cond_grad_graph, body_grad_graph, \u001b[39mlen\u001b[39m(loop_vars))\n\u001b[0;32m    444\u001b[0m outputs \u001b[39m=\u001b[39m _build_while_op(\n\u001b[0;32m    445\u001b[0m     loop_vars,\n\u001b[0;32m    446\u001b[0m     cond_grad_graph,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m     num_original_outputs\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(body_grad_graph\u001b[39m.\u001b[39moutputs),\n\u001b[0;32m    452\u001b[0m     stateful_parallelism\u001b[39m=\u001b[39mstateful_parallelism)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1056\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1053\u001b[0m   args \u001b[39m=\u001b[39m signature\n\u001b[0;32m   1054\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1056\u001b[0m func_args \u001b[39m=\u001b[39m _get_defun_inputs_from_args(args, arg_names)\n\u001b[0;32m   1057\u001b[0m func_kwargs \u001b[39m=\u001b[39m _get_defun_inputs_from_kwargs(kwargs)\n\u001b[0;32m   1059\u001b[0m \u001b[39m# Convert all Tensors into TensorSpecs before saving the structured inputs.\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39m# If storing pure concrete functions that are not called through polymorphic\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[39m# functions, we don't have access to FunctionSpec, so we need to call the\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[39m# TensorSpecs by their `arg_names` for later binding.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1322\u001b[0m, in \u001b[0;36m_get_defun_inputs_from_args\u001b[1;34m(args, names)\u001b[0m\n\u001b[0;32m   1320\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_defun_inputs_from_args\u001b[39m(args, names):\n\u001b[0;32m   1321\u001b[0m   \u001b[39m\"\"\"Maps Python function positional args to graph-construction inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m _get_defun_inputs(args, names, structured_args\u001b[39m=\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1375\u001b[0m, in \u001b[0;36m_get_defun_inputs\u001b[1;34m(args, names, structured_args)\u001b[0m\n\u001b[0;32m   1373\u001b[0m   requested_name \u001b[39m=\u001b[39m name\n\u001b[0;32m   1374\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m   placeholder \u001b[39m=\u001b[39m graph_placeholder(\n\u001b[0;32m   1376\u001b[0m       arg\u001b[39m.\u001b[39;49mdtype, arg\u001b[39m.\u001b[39;49mshape, name\u001b[39m=\u001b[39;49mrequested_name)\n\u001b[0;32m   1377\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   1378\u001b[0m   \u001b[39m# Sometimes parameter names are not valid op names, so fall back to\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m   \u001b[39m# unnamed placeholders.\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m   placeholder \u001b[39m=\u001b[39m graph_placeholder(arg\u001b[39m.\u001b[39mdtype, arg\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\eager\\graph_only_ops.py:34\u001b[0m, in \u001b[0;36mgraph_placeholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m     32\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m     33\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: dtype_value, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m: shape}\n\u001b[1;32m---> 34\u001b[0m op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPlaceholder\u001b[39;49m\u001b[39m\"\u001b[39;49m, [], [dtype], input_types\u001b[39m=\u001b[39;49m[],\n\u001b[0;32m     36\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m     37\u001b[0m result, \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n\u001b[0;32m     38\u001b[0m \u001b[39mif\u001b[39;00m op_callbacks\u001b[39m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[0;32m     39\u001b[0m   \u001b[39m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[0;32m     40\u001b[0m   \u001b[39m# are unified. Remove this `if` block.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:694\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    692\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    693\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    695\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    696\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3754\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3751\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3752\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3753\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3754\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3755\u001b[0m       node_def,\n\u001b[0;32m   3756\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3757\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3758\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3759\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3760\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3761\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3762\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3763\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3764\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2129\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2127\u001b[0m   \u001b[39mif\u001b[39;00m op_def \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2128\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[1;32m-> 2129\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, node_def, inputs,\n\u001b[0;32m   2130\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m   2131\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname)\n\u001b[0;32m   2133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traceback \u001b[39m=\u001b[39m tf_stack\u001b[39m.\u001b[39mextract_stack_for_node(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\augustin\\Desktop\\Projets\\Formations\\Openclassrooms\\Projet 7\\D-tectez-les-Bad-Buzz-gr-ce-au-Deep-Learning\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1933\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1931\u001b[0m inputs \u001b[39m=\u001b[39m _reconstruct_sequence_inputs(op_def, inputs, node_def\u001b[39m.\u001b[39mattr)\n\u001b[0;32m   1932\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1933\u001b[0m op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(graph\u001b[39m.\u001b[39;49m_c_graph,\n\u001b[0;32m   1934\u001b[0m                                             compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m   1935\u001b[0m                                             compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m   1936\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   1937\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1, min_lr = 0.01, monitor = 'val_loss', verbose = 1)\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size = 1024, epochs=10, validation_data=(X_test, Y_test), callbacks=[ReduceLROnPlateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, Y_test, Y_pred):\n",
    "    cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "    ax = sns.heatmap(cnf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion matrix')\n",
    "    plt.gcf().set_facecolor('white')\n",
    "    plt.show()\n",
    "\n",
    "    roc = roc_curve(Y_test, Y_pred)\n",
    "    roc_auc = auc(roc[0], roc[1])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(roc[0], roc[1], color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy',linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.gcf().set_facecolor('white')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9c4a45f90ea7accfc80c7c33c04e533dd49a951aeea4333815f26f962f1c8d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
